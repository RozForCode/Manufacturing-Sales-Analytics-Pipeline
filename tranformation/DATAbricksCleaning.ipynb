{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aa019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# databricks_cleaning.ipynb (simplified local example)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, round, when\n",
    "\n",
    "spark = SparkSession.builder.appName(\"IKODataCleaning\").getOrCreate()\n",
    "\n",
    "# Load data\n",
    "sales = spark.read.csv(\"../01_raw_data/sales.csv\", header=True, inferSchema=True)\n",
    "products = spark.read.csv(\"../01_raw_data/products.csv\", header=True, inferSchema=True)\n",
    "regions = spark.read.csv(\"../01_raw_data/regions.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Clean / format\n",
    "sales = sales.withColumn(\"SaleDate\", to_date(col(\"SaleDate\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Join product data for profitability metrics\n",
    "sales_enriched = (\n",
    "    sales.join(products, \"ProductID\", \"left\")\n",
    "    .withColumn(\"ProfitPerUnit\", round(col(\"UnitPrice\") - col(\"ProductionCost\"), 2))\n",
    "    .withColumn(\"TotalProfit\", round(col(\"QuantitySold\") * col(\"ProfitPerUnit\"), 2))\n",
    ")\n",
    "\n",
    "# Replace missing or invalid data\n",
    "sales_enriched = sales_enriched.fillna({\"SalesChannel\": \"Unknown\", \"Region\": \"Unspecified\"})\n",
    "\n",
    "# Save transformed version (simulate Data Lake output)\n",
    "sales_enriched.write.csv(\"../03_data_warehouse/cleaned_sales.csv\", header=True, mode=\"overwrite\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
